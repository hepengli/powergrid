# PowerGrid Gym Environment

A lightweight, production-style **Gymnasium** environment for **power grid control**, built on [pandapower](https://www.pandapower.org/).  
It provides modular device models (DG, RES, ESS, Shunt, Transformer, Grid) with clean action/observation spaces, centralized safety metrics, and pluggable rewards â€” designed for Reinforcement Learning (RL) and Multi-Agent RL research.

---

## Highlights

- âš¡ **Plug-and-play devices**: `DG`, `RES` (solar/wind), `ESS`, `Shunt`, `Transformer` (OLTC), `Grid`, `Switch`
- ğŸ”Œ **Pandapower integration** with idempotent device â†’ network attachment
- ğŸ§© **Gymnasium-compatible** single-agent base (`GridBaseEnv`)
- ğŸ›ï¸ **Mixed action spaces**: continuous (`Box`) and discrete (`Discrete` / `MultiDiscrete`) combined in a `Dict`
- ğŸ”„ **NormalizeActionWrapper**: agents act in `[-1, 1]`, environment rescales to physical ranges
- ğŸ›¡ï¸ **Safety framework** (`SafetySpec`, `total_safety`) for penalties: over-rating, power factor, SOC, voltage, line loading, etc.
- ğŸ’° **Cost helpers**: quadratic, piecewise linear, ramping, tap wear, energy settlement
- âœ… **Unit tests** for devices and environment logic
- ğŸ§ª **RL-ready**: works with Stable-Baselines3, RLlib, and custom Gym agents

---

## Installation

### Conda (recommended on macOS/Ubuntu)

```bash
# Create an environment
conda create -n powergrid python=3.12 -y
conda activate powergrid
pip install -U pip
pip install -e .

# Or direct setup with pip
pip install -r requirements.txt
```

# Quick Start
```bash
from powergrid.envs.single_agent.ieee13_env import IEEE13Env

# Create and wrap: agent acts in [-1,1] for the continuous part
env = IEEE13Env({"episode_length": 24, "train": True})
obs, info = env.reset()

# Take a random step
action = env.action_space.sample()
obs, reward, terminated, truncated, info = env.step(action)
print("reward=", reward, "converged=", info.get("converged"))
```

## Action Space

- **Continuous:** concatenated device controls (e.g., DG P/Q, ESS P/Q, RES Q)  
- **Discrete:** optional categoricals (e.g., transformer taps)  

- **Exposed as:**
    - pure continuous â†’ `Box`  
    - mixed â†’ `Dict({"continuous": Box, "discrete": Discrete|MultiDiscrete})`  

**Tip:** wrap with `NormalizeActionWrapper` if your agent outputs values in `[-1, 1]`;  
the environment automatically rescales to true physical ranges internally.

powergrid/
â”œâ”€â”€ README.md
â”œâ”€â”€ setup.py
â”œâ”€â”€ LICENSE.txt
â”œâ”€â”€ environment.yml
â”œâ”€â”€ data/ # time-series (load/solar/wind/price)
â”œâ”€â”€ micpopt/
â”œâ”€â”€ tests/
â”‚ â”œâ”€â”€ test_generator.py
â”‚ â”œâ”€â”€ test_storage.py
â”‚ â”œâ”€â”€ test_grid.py
â”‚ â””â”€â”€ test_safety.py
â”œâ”€â”€ src/
â”‚ â””â”€â”€ powergrid/
â”‚ â”œâ”€â”€ init.py
â”‚ â”œâ”€â”€ cost.py # quadratic/piecewise, ramping, energy, tap wear
â”‚ â”œâ”€â”€ safety.py # SafetySpec, total_safety, s_over_rating, pf_penalty, soc_bounds
â”‚ â”œâ”€â”€ utils.py # helper functions
â”‚ â”œâ”€â”€ core/
â”‚ â”‚ â”œâ”€â”€ init.py
â”‚ â”‚ â””â”€â”€ state.py # DeviceState as_vector / feature packing
â”‚ â”œâ”€â”€ actions.py # Action (continuous/discrete sampling, ranges)
â”‚ â”œâ”€â”€ devices/
â”‚ â”‚ â”œâ”€â”€ init.py
â”‚ â”‚ â”œâ”€â”€ base.py # Device base class (cost/safety fields)
â”‚ â”‚ â”œâ”€â”€ generator.py # DG, RES (uses utils.cost & utils.safety)
â”‚ â”‚ â”œâ”€â”€ storage.py # ESS (SOC dynamics, feasible_action)
â”‚ â”‚ â”œâ”€â”€ shunt.py # Shunt (controllable steps if applicable)
â”‚ â”‚ â”œâ”€â”€ transformer.py # OLTC Transformer (tap cost; safety via SafetySpec)
â”‚ â”‚ â””â”€â”€ switch.py # Switch (callback/boolean state)
â”‚ â”œâ”€â”€ grid.py # Grid interface (price/P/Q settlement)
â”‚ â”œâ”€â”€ networks/
â”‚ â”‚ â”œâ”€â”€ init.py
â”‚ â”‚ â”œâ”€â”€ ieee13.py # IEEE 13 bus system
â”‚ â”‚ â””â”€â”€ ieee34.py # IEEE 34 bus system
â”‚ â””â”€â”€ envs/
â”‚ â”œâ”€â”€ init.py
â”‚ â”œâ”€â”€ base_env.py # Gymnasium Env base
â”‚ â””â”€â”€ single_agent/
â”‚ â”œâ”€â”€ init.py
â”‚ â””â”€â”€ ieee13_env.py # IEEE13Env (_build_net, _reward_and_safety)